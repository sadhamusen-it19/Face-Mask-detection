{
 "cells": [
  {
   "source": [
    "## Importing the Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JAS4mNdQ1e8h"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m_q08paiFurw"
   },
   "outputs": [],
   "source": [
    "dataset = #Dataset Path for face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_face = #Path to save deted face from the Dataset"
   ]
  },
  {
   "source": [
    "## Use Either of the way to detect the faces"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EE3D1UfQh7w1",
    "outputId": "942dd5c4-ddb6-4a83-df98-90a70a6f4551"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "cascPath = os.path.dirname(\n",
    "    cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "for folder in os.listdir(dataset):\n",
    "  count = 0\n",
    "  print(folder)\n",
    "  for img in os.listdir(dataset + folder):\n",
    "      im1 = Image.open(dataset + folder + '/' + img)\n",
    "      im2 = np.asarray(im1)\n",
    "      faces = faceCascade.detectMultiScale(im2,\n",
    "                                            scaleFactor=1.1,\n",
    "                                            minNeighbors=5,\n",
    "                                            minSize=(60, 60),\n",
    "                                            flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "\n",
    "      for (x, y, w, h) in faces:\n",
    "            #face_frame = Image.fromarray(im2)\n",
    "            face_frame = im2[y:y+h,x:x+w]\n",
    "            face_frame = Image.fromarray(face_frame)\n",
    "            face_frame.save(only_face + folder + '/' + str(count) + '.jpg')\n",
    "            print(img) \n",
    "      count += 1      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TI1auBbjI15Y",
    "outputId": "e3258232-eda6-4dab-9152-88768bcc18d4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cascPath = os.path.dirname(\n",
    "    cv2.__file__) + \"/data/haarcascade_frontalface_alt2.xml\"\n",
    "faceCascade = cv2.CascadeClassifier(cascPath)\n",
    "\n",
    "for folder in os.listdir(dataset):\n",
    "  count = 0\n",
    "  print(folder)\n",
    "  for img in os.listdir(dataset + folder):\n",
    "    print(img)\n",
    "    #grey_img = cv2.imread(dataset + folder + '/' + img, cv2.IMREAD_GRAYSCALE)\n",
    "    grey_img = cv2.imread(dataset + folder + '/' + img)\n",
    "    faces = faceCascade.detectMultiScale(grey_img,\n",
    "                                      scaleFactor=1.1,\n",
    "                                      minNeighbors=5,\n",
    "                                      minSize=(60, 60),\n",
    "                                      flags=cv2.CASCADE_SCALE_IMAGE)\n",
    "    for (x, y, w, h) in faces:\n",
    "      face_frame = grey_img[y:y+h,x:x+w]\n",
    "      face_frame1 = cv2.cvtColor(face_frame, cv2.COLOR_GRAY2BGR )\n",
    "      cv2.imwrite('onlyface1/' + folder + '/' + str(count) + '.jpg',face_frame1)\n",
    "    count += 1\n",
    "  "
   ]
  },
  {
   "source": [
    "## If you have Validation Dataset remove the Validation split here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPBS2nJc1fCl"
   },
   "outputs": [],
   "source": [
    "data_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    #shear_range=0.1,\n",
    "    brightness_range=[0.1,0.2],\n",
    "    #height_shift_range=0.5,\n",
    "    #width_shift_range=0.5,\n",
    "    rotation_range=0.10,\n",
    "    horizontal_flip = True,\n",
    "    validation_split=0.29  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdxV4E-L2rlI",
    "outputId": "7a6bbb98-8184-453c-8c64-36a130379e01"
   },
   "outputs": [],
   "source": [
    "train_generator = data_datagen.flow_from_directory(\n",
    "    only_face,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 16,\n",
    "    class_mode = 'categorical',\n",
    "    #color_mode = 'grayscale',\n",
    "    subset = 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9h9Rw8g2rnb",
    "outputId": "4e38e345-ca68-47ad-b4f6-db399f064873"
   },
   "outputs": [],
   "source": [
    "test_generator = data_datagen.flow_from_directory(\n",
    "    only_face,\n",
    "    target_size = (224,224),\n",
    "    batch_size = 16,\n",
    "    class_mode = 'categorical',\n",
    "    #color_mode = 'grayscale',\n",
    "    subset = 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-YDnLPI-2rpi",
    "outputId": "e3573b39-154c-4df8-f1c3-94324c7b203b"
   },
   "outputs": [],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viHNRFgYrdoB",
    "outputId": "47549ecf-45d3-467d-aad6-dbdc3c6b6ae9"
   },
   "outputs": [],
   "source": [
    "train_generator[0][0].shape"
   ]
  },
  {
   "source": [
    "## Train Using Inception V3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yikQSD9X3zfU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6aDpTmY3zlC"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0J2aH0WS3zuF"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow\n",
    "from time import time\n",
    "#from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "#tensorboard = TensorBoard(log_dir=\"logs\\{}\".format(time()))\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(1024, activation='relu',\n",
    "    kernel_regularizer= tensorflow.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "    bias_regularizer=tensorflow.keras.regularizers.l2(1e-4),\n",
    "    activity_regularizer=tensorflow.keras.regularizers.l2(1e-5))(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = Adam(lr=0.001), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zP2U-BEQ3zz3",
    "outputId": "ee32664a-776d-47fe-986c-c66e51e70c98",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yjYZ0DYL2rr1",
    "outputId": "11f178fb-c7ba-4031-d67e-e4397a5c38bb"
   },
   "outputs": [],
   "source": [
    "inc_history = model.fit(train_generator,\n",
    "                                  validation_data = test_generator,\n",
    "                                  #steps_per_epoch = 100,\n",
    "                                  #callbacks=[tensorboard],\n",
    "                                  epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 562
    },
    "id": "Rfm96ZrG4ZDb",
    "outputId": "ec887525-8574-45d0-b7ac-cc09ae7fe05a"
   },
   "outputs": [],
   "source": [
    "acc      = inc_history.history['accuracy']\n",
    "val_acc  = inc_history.history['val_accuracy']\n",
    "loss     = inc_history.history['loss']\n",
    "val_loss = inc_history.history['val_loss']\n",
    "\n",
    "epochs   = range(len(acc)) # Get number of epochs\n",
    "\n",
    "plt.plot  (epochs, acc)\n",
    "plt.plot  (epochs, val_acc)\n",
    "plt.title ('Training and validation accuracy')\n",
    "plt.figure()\n",
    "plt.plot  (epochs, loss)\n",
    "plt.plot  (epochs, val_loss)\n",
    "plt.title ('Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d_MnmR2aayjK"
   },
   "outputs": [],
   "source": [
    "model.save('main_model.h5')"
   ]
  },
  {
   "source": [
    "## Sample Prediction and testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "cJMEQXN94ZF4",
    "outputId": "26dd0c10-a5cf-4f1e-d5d9-eb2e009cd948"
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n",
    "image = Image.open('dataset\\Deepak\\IMG_20201116_172722.jpg')#.convert('L')\n",
    "print(image.size)\n",
    "size = (224, 224)\n",
    "image = ImageOps.fit(image, size, Image.ANTIALIAS)\n",
    "print(image.size)\n",
    "image_array = np.asarray(image)\n",
    "print(image_array.size)\n",
    "image.show()\n",
    "normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n",
    "data[0] = normalized_image_array\n",
    "model = tensorflow.keras.models.load_model(\"normal_main_model_150.h5\")\n",
    "prediction = model.predict(data)\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "face-recognition.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('tensorflow_gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "fc2e23c428498406c0f7c4ece0499b947a461549a5e6604b503f543f591ca8d0"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}